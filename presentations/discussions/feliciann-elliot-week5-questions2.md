Questions

1. FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness 
What problem does FlashAttention aim to solve?

2. Longformer: The Long-Document Transformer 
Why was the Longformer paper important in the development of AI?